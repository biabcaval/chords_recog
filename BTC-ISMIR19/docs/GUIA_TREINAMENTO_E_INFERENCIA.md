# Guia Completo: Treinamento e Infer√™ncia do Modelo BTC

Este guia explica como treinar o modelo BTC para reconhecimento de acordes e como realizar infer√™ncias ap√≥s o treinamento.

## üìã √çndice

1. [Pr√©-requisitos](#pr√©-requisitos)
2. [Estrutura de Diret√≥rios](#estrutura-de-diret√≥rios)
3. [Treinamento](#treinamento)
4. [Infer√™ncia/Teste](#infer√™nciateste)
5. [Onde os Arquivos s√£o Salvos](#onde-os-arquivos-s√£o-salvos)
6. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)

---

## Pr√©-requisitos

### Depend√™ncias

Instale as depend√™ncias necess√°rias:

```bash
pip install -r requirements.txt
```

Principais depend√™ncias:
- pytorch >= 1.0.0
- numpy >= 1.16.2
- librosa >= 0.6.3
- mir_eval >= 0.5
- pretty_midi >= 0.2.8

### Estrutura de Dados

Certifique-se de que os datasets est√£o organizados no diret√≥rio configurado em `run_config.yaml`:
- `root_path`: `/home/daniel.melo/datasets`
- Os datasets devem estar pr√©-processados (use `preprocess_datasets.py` se necess√°rio)

---

## Estrutura de Diret√≥rios

### Diret√≥rios Principais

```
BTC-ISMIR19/
‚îú‚îÄ‚îÄ assets/                    # Checkpoints e modelos treinados
‚îÇ   ‚îú‚îÄ‚îÄ model/                 # Checkpoints padr√£o (formato antigo)
‚îÇ   ‚îú‚îÄ‚îÄ model_1/               # Checkpoints de experimento 1
‚îÇ   ‚îú‚îÄ‚îÄ model_2/               # Checkpoints de experimento 2
‚îÇ   ‚îî‚îÄ‚îÄ tensorboard/           # Logs do TensorBoard
‚îú‚îÄ‚îÄ RESULTS/                   # Resultados de infer√™ncia (.lab e .midi)
‚îú‚îÄ‚îÄ inferences_*/              # Diret√≥rios customizados de infer√™ncia
‚îú‚îÄ‚îÄ train.py                   # Script de treinamento b√°sico
‚îú‚îÄ‚îÄ train_curriculum.py        # Script de treinamento com curriculum learning
‚îú‚îÄ‚îÄ train_kfold.py            # Script para treinar m√∫ltiplos k-folds
‚îú‚îÄ‚îÄ test.py                    # Script de infer√™ncia em arquivos de √°udio
‚îú‚îÄ‚îÄ test_full.py              # Script de teste em datasets completos
‚îî‚îÄ‚îÄ run_config.yaml           # Arquivo de configura√ß√£o
```

---

## Treinamento

### 1. Configura√ß√£o Inicial

Edite o arquivo `run_config.yaml` para ajustar os par√¢metros:

```yaml
path:
  ckpt_path: 'model'           # Subdiret√≥rio para checkpoints
  result_path: '/home/daniel.melo/BTC_ORIGINAL/BTC-ISMIR19/RESULTS'
  asset_path: '/home/daniel.melo/BTC_ORIGINAL/BTC-ISMIR19/assets'
  root_path: '/home/daniel.melo/datasets'

experiment:
  learning_rate: 0.0001
  max_epoch: 100
  batch_size: 128
  save_step: 40                # Salva checkpoint a cada N √©pocas

feature:
  large_voca: True             # True = 170 acordes, False = 25 acordes (majmin)
```

### 2. Treinamento B√°sico

**Script:** `train.py`

```bash
python train.py \
    --index 1 \
    --kfold 0 \
    --model btc \
    --dataset1 billboard \
    --dataset2 jaah \
    --test_dataset rwc \
    --voca \
    --early_stop
```

**Par√¢metros:**
- `--index`: N√∫mero do experimento (usado para nomear checkpoints)
- `--kfold`: √çndice do k-fold (0-4)
- `--model`: Tipo de modelo (`btc`, `cnn`, `crnn`)
- `--dataset1`, `--dataset2`: Datasets de treinamento
- `--test_dataset`: Dataset de teste
- `--voca`: Usa vocabul√°rio grande (170 acordes) se True
- `--early_stop`: Para o treinamento se n√£o houver melhoria em 10 √©pocas

### 3. Treinamento com Curriculum Learning

**Script:** `train_curriculum.py`

```bash
python train_curriculum.py \
    --index 1 \
    --kfold 0 \
    --model btc \
    --dataset1 billboard \
    --dataset2 jaah \
    --test_dataset rwc \
    --voca \
    --curriculum \
    --early_stop
```

O curriculum learning √© configurado em `run_config.yaml`:

```yaml
curriculum:
  enabled: True
  strategy: 'mixed'
  pacing: 'linear'
  start_ratio: 0.3
  pace_epochs: 30
```

### 4. Treinamento M√∫ltiplos K-Folds

**Script:** `train_kfold.py`

Treina todos os k-folds (0-4) sequencialmente:

```bash
python train_kfold.py \
    --index 2 \
    --kfold_start 0 \
    --kfold_end 4 \
    --model btc \
    --dataset1 billboard \
    --dataset2 jaah \
    --test_dataset rwc \
    --voca \
    --curriculum \
    --early_stop
```

Este script cria uma estrutura organizada:
```
assets/
‚îî‚îÄ‚îÄ exp2_btc_billboard_jaah_rwc_voca_curriculum/
    ‚îú‚îÄ‚îÄ kfold_0/
    ‚îÇ   ‚îî‚îÄ‚îÄ model_037.pth.tar
    ‚îú‚îÄ‚îÄ kfold_1/
    ‚îÇ   ‚îî‚îÄ‚îÄ model_042.pth.tar
    ‚îî‚îÄ‚îÄ ...
```

### 5. Monitoramento do Treinamento

**TensorBoard:**
```bash
tensorboard --logdir assets/tensorboard/idx_1
```

Visualize:
- Loss de treinamento e valida√ß√£o
- Acur√°cia de treinamento e valida√ß√£o
- Top-2 accuracy

---

## Infer√™ncia/Teste

Ap√≥s o treinamento, voc√™ pode fazer infer√™ncias de duas formas:

### 1. Teste em Dataset Completo (com M√©tricas)

**Script:** `test_full.py`

Este script testa o modelo em um dataset completo e calcula m√©tricas (root, majmin, etc.).

**Edite os par√¢metros no in√≠cio do arquivo:**

```python
CHECKPOINT_PATH = "/home/daniel.melo/BTC_ORIGINAL/BTC-ISMIR19/assets/exp2_btc_billboard_jaah_rwc_voca_curriculum/kfold_2/model_037.pth.tar"
CONFIG_PATH = "run_config.yaml"
TEST_DATASET = "rwc"
KFOLD_INDEX = 2
MODEL_TYPE = "btc"
```

**Execute:**
```bash
python test_full.py
```

**Sa√≠da:**
- M√©tricas de acur√°cia no console
- Logs detalhados do processo

### 2. Infer√™ncia em Arquivos de √Åudio

**Script:** `test.py`

Este script processa arquivos de √°udio e gera arquivos `.lab` e `.midi` com os acordes reconhecidos.

**Edite os par√¢metros no in√≠cio do arquivo:**

```python
CHECKPOINT_PATH = "/home/daniel.melo/BTC_ORIGINAL/BTC-ISMIR19/assets/exp2_btc_billboard_jaah_rwc_voca_curriculum/kfold_2/model_037.pth.tar"
CONFIG_PATH = "/home/daniel.melo/BTC_ORIGINAL/chords_recog/BTC-ISMIR19/run_config.yaml"
AUDIO_DIR = "/home/daniel.melo/datasets/rwc/audio"
SAVE_DIR = "/home/daniel.melo/BTC_ORIGINAL/BTC-ISMIR19/RESULTS"
KFOLD_INDEX = 2
LARGE_VOCA = True
```

**Execute:**
```bash
python test.py
```

**Sa√≠da:**
- Arquivos `.lab`: Anota√ß√µes de acordes no formato tempo-in√≠cio tempo-fim acorde
- Arquivos `.midi`: Representa√ß√£o MIDI dos acordes

**Formato do arquivo .lab:**
```
0.000 2.500 C:maj
2.500 5.000 F:maj
5.000 7.500 G:maj
```

---

## Onde os Arquivos s√£o Salvos

### Checkpoints (Modelos Treinados)

**Formato Antigo (train.py):**
```
assets/
‚îî‚îÄ‚îÄ model/
    ‚îú‚îÄ‚îÄ idx_1_001.pth.tar
    ‚îú‚îÄ‚îÄ idx_1_002.pth.tar
    ‚îî‚îÄ‚îÄ ...
```

**Formato Novo (train_curriculum.py / train_kfold.py):**
```
assets/
‚îî‚îÄ‚îÄ exp{index}_{model}_{datasets}_{voca}_{curriculum}/
    ‚îî‚îÄ‚îÄ kfold_{num}/
        ‚îú‚îÄ‚îÄ model_001.pth.tar
        ‚îú‚îÄ‚îÄ model_002.pth.tar
        ‚îî‚îÄ‚îÄ ...
```

**Estrutura do Checkpoint:**
```python
{
    'model': model.state_dict(),
    'optimizer': optimizer.state_dict(),
    'epoch': epoch_number
}
```

### Arquivos de Normaliza√ß√£o

Os arquivos de normaliza√ß√£o (mean e std) s√£o salvos em:
```
{root_path}/result/{mp3_string}_{feature_string}mix_kfold_{kfold}_normalization.pt
```

Exemplo:
```
/home/daniel.melo/datasets/result/22050_10.0_5.0_cqt_144_24_2048_mix_kfold_2_normalization.pt
```

**Importante:** Este arquivo √© necess√°rio para fazer infer√™ncias! Ele cont√©m a m√©dia e desvio padr√£o usados na normaliza√ß√£o durante o treinamento.

### Resultados de Infer√™ncia

**Diret√≥rio padr√£o (test.py):**
```
/home/daniel.melo/BTC_ORIGINAL/BTC-ISMIR19/RESULTS/
‚îú‚îÄ‚îÄ song1.lab
‚îú‚îÄ‚îÄ song1.midi
‚îú‚îÄ‚îÄ song2.lab
‚îî‚îÄ‚îÄ song2.midi
```

**Diret√≥rios customizados:**
Voc√™ pode criar diret√≥rios customizados para organizar infer√™ncias:
```
/home/daniel.melo/BTC_ORIGINAL/chords_recog/BTC-ISMIR19/inferences_1trainBillJaah_testRwc/
‚îú‚îÄ‚îÄ rwc-pop_001.lab
‚îú‚îÄ‚îÄ rwc-pop_001.midi
‚îî‚îÄ‚îÄ ...
```

### Logs do TensorBoard

```
assets/tensorboard/
‚îú‚îÄ‚îÄ idx_1/
‚îÇ   ‚îî‚îÄ‚îÄ events.out.tfevents.*
‚îî‚îÄ‚îÄ idx_2/
    ‚îî‚îÄ‚îÄ events.out.tfevents.*
```

---

## Exemplos Pr√°ticos

### Exemplo 1: Treinamento Completo

```bash
# 1. Treinar modelo com k-fold 0
python train_curriculum.py \
    --index 1 \
    --kfold 0 \
    --model btc \
    --dataset1 billboard \
    --dataset2 jaah \
    --test_dataset rwc \
    --voca \
    --curriculum \
    --early_stop

# 2. Ap√≥s o treinamento, o melhor checkpoint ser√° salvo em:
# assets/exp1_btc_billboard_jaah_rwc_voca_curriculum/kfold_0/model_XXX.pth.tar

# 3. Fazer infer√™ncia no dataset RWC
# Edite test_full.py com o caminho do checkpoint e execute:
python test_full.py
```

### Exemplo 2: Infer√™ncia em √Åudio Customizado

```bash
# 1. Coloque seus arquivos de √°udio em um diret√≥rio
mkdir -p /home/daniel.melo/my_audio_files
# Copie arquivos .mp3 ou .wav para este diret√≥rio

# 2. Edite test.py:
# - CHECKPOINT_PATH: caminho do checkpoint treinado
# - AUDIO_DIR: "/home/daniel.melo/my_audio_files"
# - SAVE_DIR: diret√≥rio onde salvar resultados
# - KFOLD_INDEX: mesmo k-fold usado no treinamento

# 3. Execute
python test.py

# 4. Resultados estar√£o em SAVE_DIR
```

### Exemplo 3: Treinar Todos os K-Folds

```bash
# Treina k-folds 0, 1, 2, 3, 4 sequencialmente
python train_kfold.py \
    --index 2 \
    --kfold_start 0 \
    --kfold_end 4 \
    --model btc \
    --dataset1 billboard \
    --dataset2 jaah \
    --test_dataset rwc \
    --voca \
    --curriculum

# Depois teste cada k-fold:
# Edite test_full.py para cada checkpoint e execute
```

### Exemplo 4: Usar Checkpoint Espec√≠fico

```python
# Em test_full.py ou test.py, defina:
CHECKPOINT_PATH = "/home/daniel.melo/BTC_ORIGINAL/BTC-ISMIR19/assets/exp2_btc_billboard_jaah_rwc_voca_curriculum/kfold_2/model_037.pth.tar"

# Certifique-se de usar o mesmo KFOLD_INDEX usado no treinamento:
KFOLD_INDEX = 2
```

---

## Dicas Importantes

1. **K-Fold Index:** Sempre use o mesmo `kfold` index no treinamento e na infer√™ncia, pois o arquivo de normaliza√ß√£o √© espec√≠fico para cada k-fold.

2. **Large Voca:** Se treinou com `--voca`, use `LARGE_VOCA = True` na infer√™ncia. Se treinou sem, use `LARGE_VOCA = False`.

3. **Arquivo de Normaliza√ß√£o:** Este arquivo √© criado automaticamente durante o treinamento. Certifique-se de que ele existe antes de fazer infer√™ncias.

4. **Checkpoints:** O script de treinamento salva:
   - Checkpoint do melhor modelo (melhor acur√°cia de valida√ß√£o)
   - Checkpoints peri√≥dicos (a cada `save_step` √©pocas)

5. **Estrutura de Pastas de Infer√™ncia:** Voc√™ pode criar diret√≥rios customizados para organizar diferentes experimentos de infer√™ncia, como:
   - `inferences_1trainBillJaah_testRwc/`
   - `inferences_2trainBillJaahDjavan_testRwc/`

---

## Troubleshooting

### Erro: "Normalization file not found"
- Certifique-se de que o arquivo de normaliza√ß√£o existe no caminho esperado
- Verifique se o `KFOLD_INDEX` est√° correto
- O arquivo √© criado durante o primeiro treinamento

### Erro: "Checkpoint not found"
- Verifique o caminho do checkpoint
- Certifique-se de que o treinamento foi conclu√≠do
- Verifique se est√° usando o caminho correto (formato antigo vs novo)

### Erro: "Dataset path does not exist"
- Verifique se os datasets est√£o pr√©-processados
- Execute `preprocess_datasets.py` se necess√°rio
- Verifique o `root_path` em `run_config.yaml`

---

## Resumo R√°pido

**Treinar:**
```bash
python train_curriculum.py --index 1 --kfold 0 --model btc --dataset1 billboard --dataset2 jaah --test_dataset rwc --voca --curriculum
```

**Testar (m√©tricas):**
```bash
# Edite test_full.py com CHECKPOINT_PATH e execute:
python test_full.py
```

**Inferir (√°udio):**
```bash
# Edite test.py com CHECKPOINT_PATH, AUDIO_DIR, SAVE_DIR e execute:
python test.py
```

**Checkpoints salvos em:**
- `assets/exp{index}_.../kfold_{num}/model_XXX.pth.tar`

**Resultados salvos em:**
- `RESULTS/` (padr√£o) ou diret√≥rio customizado definido em `SAVE_DIR`

---

**√öltima atualiza√ß√£o:** Dezembro 2024

